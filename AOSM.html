<!doctype html>
<html lang="en">

    <head>
        <meta charset="utf-8">

        <title>Adaptive optimised Schwarz methods</title>

        <link rel="stylesheet" href="dist/reset.css">
        <link rel="stylesheet" href="dist/reveal.css">
        <link rel="stylesheet" href="dist/theme/white.css" id="theme">

        <link rel="stylesheet" href="plugin/highlight/monokai.css">

        <style id="span-fix" type="text/css">
            
        h1 span {
            display:inline-block;
        }
        img {
            object-fit:cover;
            max-width: 100%;
        }
        </style>
    </head>

    <body>
        <div class="reveal">
            <div class="slides">

                <section>
                    <h3>Adaptive optimized Schwarz methods</h3>

                    <p>Conor McCoid</p>
                    <p>Felix Kwok</p>
                    <p><small>Universit√© Laval</small></p>

                    <img src="FIG/ULaval-C.png" height="105" width="255">
                </section>

                <section>
                    <section>
                        <h3>Schwarz methods</h3>
                    </section>

                    <section data-auto-animate>
                        <p class="r-fit-text">Consider the following sample problem:
                            \[\Delta u(x,y) = f(x,y), \quad (x,y) \in \Omega = [-1,1] \times [-1,1]\]
                            \[u(x,y)=h(x,y), \quad (x,y) \in \partial \Omega\]
                        </p>

                        <p class="fragment">We'll discretize this into</p>
                        <p class="fragment">
                            \[A \vec{u} = \vec{f}, \quad A \in \mathbb{R}^{N \times N}\]
                        </p>
                    </section>

                    <section data-auto-animate>
                        <p>
                            \[A \vec{u} = \vec{f}, \quad A \in \mathbb{R}^{N \times N}\]
                        </p>
                        <p>If $N$ is very large, this can take a long time to find $\vec{u}$</p>
                        <p class="fragment">Schwarz methods divide the domain into smaller problems</p>
                    </section>

                    <section data-auto-animate>
                        <p>Schwarz methods divide the domain into smaller problems</p>
                        <p class="r-fit-text">
                            \[\Delta u_1^n(x,y) = f(x,y), \quad (x,y) \in \Omega_1 = [-1,\alpha] \times [-1,1]\]
                            \[u_1^n(\alpha,y)=u_2^{n-1}(\alpha,y)\]
                            \[\Delta u_2^n(x,y) = f(x,y), \quad (x,y) \in \Omega_2 = [\beta,1] \times [-1,1]\]
                            \[u_2^n(\beta,y)=u_1^{n-1}(\beta,y)\]
                        </p>
                    </section>

                    <section data-auto-animate>
                        <p>Schwarz methods divide the domain into smaller problems</p>
                        <img src="FIG/AOSM/TIKZ_AOSM_20230614_1.png" width="600">
                        <!--pic of subdomain splitting-->
                    </section>

                    <section data-auto-animate>
                        <p>Schwarz methods divide the domain into smaller problems</p>
                        <p>Multiplicative Schwarz: solve one subdomain after the other</p>
                        <p class="fragment">Additive Schwarz: solve both subdomains at the same time</p>
                    </section>

                    <section data-auto-animate>
                        <p>Schwarz methods divide the domain into smaller problems</p>
                        <p>
                            \[\begin{bmatrix} A_{11} & A_{1\Gamma} \\ A_{\Gamma 1} & A_{\Gamma \Gamma} & A_{\Gamma 2} \\ & A_{2 \Gamma} & A_{22} \end{bmatrix}
                            \begin{bmatrix} \vec{u}_1 \\ \vec{u}_\Gamma \\ \vec{u}_2 \end{bmatrix}
                            = \begin{bmatrix} \vec{f}_1 \\ \vec{f}_\Gamma \\ \vec{f}_2 \end{bmatrix}\]
                        </p>
                    </section>
                    
                    <section data-auto-animate>
                        <p>Schwarz methods divide the domain into smaller problems</p>
                        <p class="r-fit-text">
                            \[\begin{bmatrix} A_{11} & A_{1 \Gamma} \\ A_{\Gamma 1} & A_{\Gamma \Gamma} + T_{2 \to 1} \end{bmatrix}
                            \begin{bmatrix} \vec{u}_1^{n+1} \\ \vec{u}_{1 \Gamma}^{n+1} \end{bmatrix}
                            = \begin{bmatrix} \vec{f}_1 \\ \vec{f}_\Gamma \end{bmatrix}
                            + \begin{bmatrix} ~ \\ -A_{\Gamma 2} \vec{u}_2^n + T_{2 \to 1} \vec{u}_{2 \Gamma}^n \end{bmatrix}\]
                            \[\begin{bmatrix} A_{22} & A_{2 \Gamma} \\ A_{\Gamma 2} & A_{\Gamma \Gamma} + T_{1 \to 2} \end{bmatrix}
                            \begin{bmatrix} \vec{u}_2^{n+1} \\ \vec{u}_{2 \Gamma}^{n+1} \end{bmatrix}
                            = \begin{bmatrix} \vec{f}_2 \\ \vec{f}_\Gamma \end{bmatrix}
                            + \begin{bmatrix} ~ \\ -A_{\Gamma 1} \vec{u}_1^n + T_{1 \to 2} \vec{u}_{1 \Gamma}^n \end{bmatrix}\]
                        </p>
                    </section>
                </section>

                <section>
                    <section>
                        <h3>Optimized Schwarz methods</h3>
                    </section>

                    <section data-auto-animate>
                        <p>Boundary conditions transmit information between the two subdomains</p>

                        <p class="fragment">We've used Dirichlet BCs, which require an overlap</p>

                        <p class="fragment">We could use Robin BCs instead, and have no overlap</p>
                    </section>

                    <section data-auto-animate>
                        <p>We could use Robin BCs instead, and have no overlap</p>

                        <p class="r-fit-text">
                            \[\Delta u_1^n(x,y) = f(x,y), \quad (x,y) \in \Omega_1 = [-1,0] \times [-1,1]\]
                            \[\frac{\partial u_1^n}{\partial x} - p u_1^n(0,y)= \frac{\partial u_2^{n-1}}{\partial x} - p u_2^{n-1}(0,y)\]
                            \[\Delta u_2^n(x,y) = f(x,y), \quad (x,y) \in \Omega_2 = [0,1] \times [-1,1]\]
                            \[\frac{\partial u_2^n}{\partial x} - p u_2^n(0,y)= \frac{\partial u_1^{n-1}}{\partial x} - p u_1^{n-1}(0,y)\]
                        </p>
                    </section>

                    <section data-auto-animate>
                        <p>We could use Robin BCs instead, and have no overlap</p>
                        <img src="FIG/AOSM/TIKZ_AOSM_20230614_2.png" width="600">
                        <!--pic of non-overlapping subdomains-->
                    </section>

                    <section>
                        <p>Now there's a choice in Robin parameter $p$, and this choice can be optimized</p>

                        <p class="fragment">Optimization is done using Fourier analysis and finds the best $p$ for all Fourier modes</p>

                        <p class="fragment">If you have a specific Fourier mode in mind, you can also pick the best $p$ for just that mode</p>
                    </section>

                    <section>
                        <p>Robin BCs aren't the only option for optimized BCs</p>

                        <p class="fragment">Tangential BCs are also a popular choice, and give a second parameter $q$ to optimize
                            \[\frac{\partial u_1^n}{\partial x} - p u_1^n(0,y) + q \frac{\partial u_1^n}{\partial y}=\]
                            \[\frac{\partial u_2^{n-1}}{\partial x} - p u_2^{n-1}(0,y) + q \frac{\partial u_2^n}{\partial y}\]
                        </p>
                    </section>

                    <section data-auto-animate>
                        <p>But the best BCs are absorbing BCs, which are used in perfectly matched layers</p>

                        <p>These are dense, and correspond to Schur complements
                            \[T_{2 \to 1} \to S_{2 \to 1} = -A_{\Gamma 2} A_{22}^{-1} A_{2 \Gamma},\]
                            \[T_{1 \to 2} \to S_{1 \to 2} = -A_{\Gamma 1} A_{11}^{-1} A_{1 \Gamma}\]
                        </p>
                    </section>

                    <section data-auto-animate>
                        <p>These are dense, and correspond to Schur complements
                            \[T_{2 \to 1} \to S_{2 \to 1} = -A_{\Gamma 2} A_{22}^{-1} A_{2 \Gamma},\]
                            \[T_{1 \to 2} \to S_{1 \to 2} = -A_{\Gamma 1} A_{11}^{-1} A_{1 \Gamma}\]
                        </p>
                        <p>This means they have about the same computation time as $M$ iterations, where $M$ is the size of the overlap</p>
                    </section>
                </section>

                <section>
                    <section>
                        <h3>Adaptive transmission conditions</h3>
                    </section>

                    <section>
                        <p>Finding optimized BCs requires Fourier analysis on each given problem</p>

                        <p class="fragment">And the optimal BCs need Schur complements which are expensive to calculate</p>

                        <p class="fragment">We want cheap, black box BCs</p>

                        <p class="fragment">To get them, we'll find them adaptively</p>
                    </section>

                    <section>
                        <p>Let's look at the differences between iterates for a single sudomain</p>

                        <p class="r-fit-text">
                            \[
                                \begin{bmatrix} A_{11} & A_{1 \Gamma} \\ A_{\Gamma 1} & A_{\Gamma \Gamma} + T_{2 \to 1} \end{bmatrix}
                                \left ( \begin{bmatrix} \vec{u}_1^{n+1} \\ \vec{u}_{1 \Gamma}^{n+1} \end{bmatrix} - \begin{bmatrix} \vec{u}_1^n \\ \vec{u}_{1 \Gamma}^n \end{bmatrix} \right )
                                = 
                            \]\[
                                \begin{bmatrix} \vec{f}_1 \\ \vec{f}_\Gamma \end{bmatrix}
                                + \begin{bmatrix} ~ \\ -A_{\Gamma 2} \vec{u}_2^n + T_{2 \to 1} \vec{u}_{2 \Gamma}^n \end{bmatrix}
                                - \left (\begin{bmatrix} \vec{f}_1 \\ \vec{f}_\Gamma \end{bmatrix}
                                + \begin{bmatrix} ~ \\ -A_{\Gamma 2} \vec{u}_2^{n-1} + T_{2 \to 1} \vec{u}_{2 \Gamma}^{n-1} \end{bmatrix} \right )
                            \]
                        </p>
                    </section>

                    <section>
                        <p>We then perform what's known as static condensation by noting that
                            \[A_{11} \vec{d}_1^{n+1} = -A_{\Gamma 1} \vec{d}_{1 \Gamma}^{n+1} \]
                        </p>
                    </section>

                    <section data-auto-animate>
                        <p>This leads to</p>
                        <p>
                            \[(A_{\Gamma \Gamma} + S_{1 \to 2} + T_{2 \to 1}) \vec{d}_{1 \Gamma}^{n+1} = (T_{2 \to 1} - S_{2 \to 1}) \vec{d}_{2 \Gamma}^n \]
                        </p>

                        <p class="fragment">
                            \[ \vec{y}^{n+1} = E_2 \vec{d}_{2 \Gamma}^n = -A_{\Gamma 2} \vec{d}_2^n + T_{2 \to 1} \vec{d}_{2 \Gamma}^n \]
                        </p>
                    </section>

                    <section data-auto-animate>
                        <p>
                            \[ \vec{y}^{n+1} = E_2 \vec{d}_{2 \Gamma}^n = -A_{\Gamma 2} \vec{d}_2^n + T_{2 \to 1} \vec{d}_{2 \Gamma}^n \]
                        </p>
                        <p>At every other iteration, we're going to update $E_2$</p>
                        
                        <p class="fragment">
                            \[ E_2 \to E_2 - \frac{ \vec{y} \vec{d}^\top }{ \Vert \vec{d} \Vert^2 } \]
                        </p>
                    </section>

                    <section data-auto-animate>
                        <p>
                            \[ E_2 \to E_2 - \frac{ \vec{y} \vec{d}^\top }{ \Vert \vec{d} \Vert^2 } \]
                        </p>
                        <p>With each iteration, there's a new pair of $\vec{y}$ and $\vec{d}$</p>
                        <p class="fragment">We can apply a modified Gram-Schmidt process to the vectors $\vec{d}$, making the vectors $\vec{w}$</p>
                        <p class="fragment">Through this process, the vectors $\vec{y}$ get modified as well, to the vectors $\vec{v}$</p>
                    </section>
                    <section data-auto-animate>
                        <p>
                            \[ E_2 \to E_2 - V W^\top \]
                        </p>
                        <p class="fragment">Since $V = E_2 W$, this is equivalent to
                            \[ E_2 \to E_2 \left ( I - W W^\top \right ) \]
                        </p>
                        <p class="fragment">We generate a low rank approximation of $E_2$</p>
                        <p class="fragment">To make the optimized BCs, we subtract this from $T_{2 \to 1}$</p>
                    </section>

                    <section>
                        <p>The transmission conditions $T_{2 \to 1}$ and $T_{1 \to 2}$ now change iteratively</p>
                        <img src="FIG/AOSM/TIKZ_AOSM_20230614_3.png" width="600">
                        <!--alt-AOSM solve ladder-->
                    </section>

                    <section>
                        <p>Recall:
                            \[(A_{\Gamma \Gamma} + S_{1 \to 2} + T_{2 \to 1}) \vec{d}_{1 \Gamma}^{n+1} = (T_{2 \to 1} - S_{2 \to 1}) \vec{d}_{2 \Gamma}^n \]
                        </p>
                        <p>The vectors $\vec{d}$ lie in a Krylov subspace</p>
                        <p class="fragment">Since we're applying a modified Gram-Schmidt to these vectors, this method is equivalent to GMRES</p>
                    </section>

                    <section>
                        <p>There's also the option to update the BCs at every iteration</p>
                        <img src="FIG/AOSM/TIKZ_AOSM_20230614_4.png" width="600">
                        <!--para-AOSM solve ladder-->
                    </section>
                </section>

                <section>
                    <section>
                        <h3>Adaptive Optimized Schwarz Methods (AOSMs)</h3>
                    </section>
                    <!--write out algorithm steps-->

                    <section>
                        <h5>1. Initial guesses</h5>

                        <p class="fragment">Make initial choices of $\vec{u}_{1 \Gamma}^0$, $T_{1 \to 2}^1$ and $T_{2 \to 1}^1$</p>
                        <p class="fragment">Find $\vec{u}_1^0 = A_{11}^{-1} \left ( \vec{f}_1 - A_{1 \Gamma} \vec{u}_{1 \Gamma}^0 \right )$</p>
                        <p class="fragment r-fit-text">Solve 
                            \[ \begin{bmatrix} A_{22} & A_{2 \Gamma} \\ A_{\Gamma 2} & A_{\Gamma \Gamma} + T_{1 \to 2}^1 \end{bmatrix}
                            \begin{bmatrix} \vec{u}_{2}^1 \\ \vec{u}_{2 \Gamma}^1 \end{bmatrix} 
                            = \begin{bmatrix} \vec{f}_2 \\ \vec{f}_\Gamma \end{bmatrix} 
                            + \begin{bmatrix} ~ \\ -A_{\Gamma 1} \vec{u}_1^0 + T_{1 \to 2}^1 \vec{u}_{1 \Gamma}^0 \end{bmatrix} \]
                        </p>
                    </section>

                    <section data-auto-animate>
                        <h5>2. Seed Krylov subspace</h5>

                        <p class="fragment r-fit-text">Solve
                            \[ \begin{bmatrix} A_{11} & A_{1 \Gamma} \\ A_{\Gamma 1} & A_{\Gamma \Gamma} + T_{2 \to 1}^1 \end{bmatrix}
                            \begin{bmatrix} \vec{u}_{1}^2 \\ \vec{u}_{1 \Gamma}^2 \end{bmatrix} 
                            = \begin{bmatrix} \vec{f}_1 \\ \vec{f}_\Gamma \end{bmatrix} 
                            + \begin{bmatrix} ~ \\ -A_{\Gamma 2} \vec{u}_2^1 + T_{2 \to 1}^1 \vec{u}_{2 \Gamma}^1 \end{bmatrix} \]
                        </p>
                        <p class="fragment">Calculate $\vec{d}_{1 \Gamma}^2 = \vec{u}_{1 \Gamma}^2 - \vec{u}_{1 \Gamma}^0$ and
                            $\vec{d}_{1}^2 = \vec{u}_{1}^2 - \vec{u}_{1}^0$
                        </p>
                    </section>

                    <section data-auto-animate>
                        <h5>2. Seed Krylov subspace</h5>
                        
                        <p>Calculate $\vec{d}_{1 \Gamma}^2 = \vec{u}_{1 \Gamma}^2 - \vec{u}_{1 \Gamma}^0$ and
                            $\vec{d}_{1}^2 = \vec{u}_{1}^2 - \vec{u}_{1}^0$
                        </p>
                        <p class="fragment">Normalize $\vec{d}_{1 \Gamma}^2$ using $\alpha_1^2$ such that $\vec{w}_1^2 = \alpha_1^2 \vec{d}_{1 \Gamma}^2$ and calculate 
                            \[ \vec{v}_1^2 = \alpha_1^2 \left ( -A_{\Gamma 1} \vec{d}_1^2 + T_{1 \to 2}^1 \vec{d}_{1 \Gamma}^2 \right ) \]
                        </p>
                        <p class="fragment">Update $T_{1 \to 2}^1$:
                            \[ T_{1 \to 2}^2 = T_{1 \to 2}^1 + \Delta T_{1 \to 2}^2 = T_{1 \to 2}^1 - \vec{v}_1^2 \left ( \vec{w}_1^2 \right )^\top \]
                        </p>
                    </section>

                    <section data-auto-animate>
                        <h5>2. Seed Krylov subspace</h5>

                        <p>Solve</p>
                        <p>
                            \[ \begin{bmatrix} A_{22} & A_{2 \Gamma} \\ A_{\Gamma 2} & A_{\Gamma \Gamma} + T_{1 \to 2}^2 \end{bmatrix}
                            \begin{bmatrix} \vec{d}_{2}^3 \\ \vec{d}_{2 \Gamma}^3 \end{bmatrix} \]
                        </p>
                        <p>
                            \[ = \begin{bmatrix} ~ \\ -A_{\Gamma 1} \vec{d}_1^2 + T_{1 \to 2}^2 \vec{d}_{1 \Gamma}^2 - \Delta T_{1 \to 2}^2 \left ( \vec{u}_{2 \Gamma}^1 - \vec{u}_{1 \Gamma}^0 \right ) \end{bmatrix} \]
                        </p>
                    </section>

                    <section data-auto-animate>
                        <h5>2. Seed Krylov subspace</h5>

                        <p>Solve</p>
                        <p>
                            \[ \begin{bmatrix} A_{22} & A_{2 \Gamma} \\ A_{\Gamma 2} & A_{\Gamma \Gamma} + T_{1 \to 2}^2 \end{bmatrix}
                            \begin{bmatrix} \vec{d}_{2}^3 \\ \vec{d}_{2 \Gamma}^3 \end{bmatrix} \]
                        </p>
                        <p>
                            \[ = \langle \vec{w}_1^2, \vec{u}_{2 \Gamma}^1 - \vec{u}_{1 \Gamma}^0 \rangle \begin{bmatrix} ~ \\ \vec{v}_1^2 \end{bmatrix} \]
                        </p>
                    </section>
                    
                    <section data-auto-animate>
                        <h5>2. Seed Krylov subspace</h5>
                        
                        <p>Normalize $\vec{d}_{2 \Gamma}^3$ using $\alpha_2^3$ such that $\vec{w}_2^3 = \alpha_2^3 \vec{d}_{2 \Gamma}^3$ and calculate 
                            \[ \vec{v}_2^3 = \alpha_2^3 \left ( -A_{\Gamma 2} \vec{d}_2^3 + T_{2 \to 1}^1 \vec{d}_{2 \Gamma}^3 \right ) \]
                        </p>
                        <p>Update $T_{2 \to 1}^1$:
                            \[ T_{2 \to 1}^3 = T_{2 \to 1}^1 - \vec{v}_2^3 \left ( \vec{w}_2^3 \right )^\top \]
                        </p>
                    </section>

                    <section data-auto-animate>
                        <h5>3. Iterate</h5>

                        <p class="fragment">Solve for $\vec{d}_i^n$ and $\vec{d}_{i \Gamma}^n$</p>
                        <p class="fragment">Apply modified Gram-Schmidt to find $\vec{v}_i^n$ and $\vec{w}_i^n$</p>
                        <p class="fragment">Update $T_{i \to j}^n$ using $\vec{v}_i^n \left ( \vec{w}_i^n \right )^\top$</p>
                    </section>

                    <section>
                        <h4>Woodbury matrix identity</h4>
                    </section>

                    <section data-auto-animate>
                        <p>The updates to $T_{1 \to 2}^n$ and $T_{2 \to 1}^n$ are low rank</p>

                        <p class="fragment">In order to preserve any matrix factorizations, we can use the Woodbury matrix identity to apply these low rank updates</p>
                        
                        <p class="fragment">
                            \[(A - V W^\top) \vec{u} = \vec{f},\]
                            \[\vec{u} = A^{-1} \vec{f} + A^{-1} V (I_{k \times k} - W^\top A^{-1} V)^{-1} W^\top A^{-1} \vec{f}\]
                        </p>
                    </section>
                </section>

                <section>
                    <section>
                        <h3>Numerical experiments</h3>
                    </section>

                    <section>
                        <p class="r-fit-text">Recall the sample problem:
                            \[\Delta u(x,y) = f(x,y), \quad (x,y) \in \Omega = [-1,1] \times [-1,1]\]
                            \[u(x,y)=h(x,y), \quad (x,y) \in \partial \Omega\]
                        </p>

                        <p>Let's apply AOSMs to this problem</p>
                    </section>

                    <section>
                        <img src="FIG/AOSM/PLOT_faltAOSMConv_Laplace.png">
                    </section>

                    <section>
                        <img src="FIG/AOSM/PLOT_fparaAOSMConv_Laplace.png">
                    </section>

                    <section>
                        <!--heat eqn-->
                        <p class="r-fit-text">
                            \[ u_t(x,y,t) = \Delta u(x,y,t), \quad (x,y) \in \Omega = [-1,1] \times [-1,1], \ t \in [0,T] \]
                		    \[ u(x,y,0) = u_0(x,y), \quad (x,y) \in \Omega, \]
		                    \[ u(x,y,t) = h(x,y), \quad (x,y) \in \partial \Omega, \ t \in [0,T] \]
                        </p>
                    </section>

                    <section>
                        <p>
                            \[\frac{u_{n+1} - u_n}{\Delta t} = A u_{n+1}\]
                            \[(I - \Delta t A) u_{n+1} = u_n\]
                        </p>
                    </section>

                    <section>
                        <img src="FIG/AOSM/PLOT_AOSMConv_Heat_v1.png">
                    </section>

                    <section>
                        <img src="FIG/AOSM/PLOT_AOSMConv_Heat_v2.png">
                    </section>

                    <section>
                        <!--Loneland example-->
                        <p class="r-fit-text">
                            \[ \nabla (\alpha(x,y) \cdot \nabla u(x,y) ) = f(x,y), \quad (x,y) \in \Omega = [-1,1] \times [-1,1], \]
                		    \[ u(x,y) = h(x,y), \quad (x,y) \in \partial \Omega, \]
                        </p>
                        <p>Solve this using FEM software</p>
                    </section>

                    <section>
                        <img src="FIG/AOSM/PLOT_MEFPP_loneland_K.png">
                    </section>
                    <section>
                        <img src="FIG/AOSM/PLOT_MEFPP_loneland_subdomains.png">
                    </section>
                    <section>
                        <img src="FIG/AOSM/PLOT_MEFPP_loneland_1.png">
                    </section>
                    <section>
                        <img src="FIG/AOSM/PLOT_MEFPP_loneland_2.png">
                    </section>
                </section>

                <section>
                    <h3>Conclusions</h3>
                    <ul>
                        <li class="fragment">AOSMs give GMRES convergence without GMRES cost</li>
                        <li class="fragment">Transmission conditions can be re-used, for restarts and time steps</li>
                    </ul>
                </section>
            </div>
        </div>

        <script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
        <script src="plugin/math/math.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.KaTeX ]
			});
		</script>
    </body>
</html>